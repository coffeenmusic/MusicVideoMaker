{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import print_frame\n",
    "from moviepy.editor import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "VID_DIR = os.path.join('Media', 'Videos')\n",
    "VID_FILES = [os.path.join(VID_DIR, f) for f in os.listdir(VID_DIR) if f.split('.')[-1].lower() in ['mp4', 'avi', 'mkv']]\n",
    "print(f'{len(VID_FILES)} videos found.', [f.split('\\\\')[-1] for f in VID_FILES])\n",
    "\n",
    "# Audio to split clips from\n",
    "AUD_DIR = os.path.join('Media', 'Audio')\n",
    "AUD_FILE = os.path.join(AUD_DIR, 'drums.wav')\n",
    "print(AUD_FILE)\n",
    "\n",
    "# Audio to stitch to final video\n",
    "FINAL_AUDIO = os.path.join(AUD_DIR, 'Greydon Square - Society Versus Nature.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Logic:\n",
    "    video_list = []\n",
    "    for split_time in split_times:\n",
    "        clip = next(clips)\n",
    "    \n",
    "        while len(clip) < split_len:\n",
    "            clip = next(clips)\n",
    "        \n",
    "        video_list += [clip[:split_len]]\n",
    "       \n",
    "    clip_list2vid(video_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Create clip list\n",
    "- Display audio waveforms\n",
    "- Create tool to find best audio split points\n",
    "\n",
    "### Ideas:\n",
    "- Change frame changed threshold with variation in audio amplitude?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potentionally Useful Functions\n",
    "- clip.get_frame(time)\n",
    "- clip.ipython_display(width=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = VideoFileClip(VID_FILES.pop(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Frames/Second:', video.reader.fps)\n",
    "print('Frame Count:', video.reader.nframes)\n",
    "print('Video Length:', video.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_frame(video.get_frame(np.random.randint(0, video.duration)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Video In To Clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def scene_changed(prev_frame, frame, delta_thresh=30):\n",
    "    delta = abs(np.mean(prev_frame) - np.mean(frame))\n",
    "    \n",
    "    if delta > delta_thresh:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def split_video(video, max_clips=0, check_freq = 1, print_split_frames=False, print_cmp_frames=False):\n",
    "    \"\"\"\n",
    "    print_split_frames - for troubleshooting, may remove later\n",
    "    print_cmp_frames - for troubleshooting, may remove later\n",
    "    max_clips - set above 0 to stop early when len(clips) greater than max_clips\n",
    "    check_freq [seconds] - how often to compare two frames for scene change\n",
    "    \"\"\"\n",
    "    clip_cnt = 0      # Number of clips created from video\n",
    "    start_time = 0    # time in seconds from video where current clip starts\n",
    "    clips = []        # list of subclips of video file created by video split\n",
    "    \n",
    "    frame_freq = int(video.reader.fps*check_freq)\n",
    "    print(f'Compare frames every {check_freq} seconds. This equals {frame_freq} frames.')\n",
    "\n",
    "    prev_frame = video.get_frame(0) # Initialize previous frame\n",
    "    \n",
    "    for i, (time, frame) in tqdm(enumerate(video.iter_frames(with_times=True))):\n",
    "\n",
    "        if i % frame_freq == 0:\n",
    "            if print_cmp_frames:\n",
    "                print_frame(np.append(prev_frame, frame, axis=1))\n",
    "\n",
    "            if i > 0: # Skip first frame\n",
    "                if start_time != stop_time and scene_changed(prev_frame, frame, delta_thresh=20):\n",
    "                    if print_split_frames:\n",
    "                        print_frame(prev_frame)\n",
    "\n",
    "                    clips += [video.subclip(start_time, stop_time)]\n",
    "\n",
    "                    start_time = time\n",
    "\n",
    "                    clip_cnt += 1\n",
    "\n",
    "            prev_frame = frame.copy()\n",
    "            stop_time = time\n",
    "\n",
    "            # Exit when we have the number of clips requested\n",
    "            if max_clips != 0 and clip_cnt > max_clips:\n",
    "                break\n",
    "    return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clips = split_video(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clips[np.random.randint(0, len(clips))].ipython_display(width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import pyaudio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_stream(audio_file, CHUNK_MUL=1):\n",
    "    CHUNK = 1024*CHUNK_MUL\n",
    "    \n",
    "    wf = wave.open(audio_file, 'rb')\n",
    "    RATE = wf.getframerate()\n",
    "    FPS = RATE / CHUNK\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                    channels=wf.getnchannels(),\n",
    "                    rate=RATE,\n",
    "                    output=True)\n",
    "    \n",
    "    return stream, wf, CHUNK, RATE\n",
    "\n",
    "def get_audio_data():\n",
    "    stream, wf, CHUNK, RATE = open_stream(AUD_FILE) \n",
    "    \n",
    "    cnt = 0\n",
    "    while True:\n",
    "        # Read next frame\n",
    "        data = wf.readframes(CHUNK)\n",
    "        if len(data) < CHUNK:\n",
    "            break\n",
    "\n",
    "        data_int = np.frombuffer(data, dtype=np.int32) # Read bytes to int\n",
    "        data_int = np.resize(data_int, (1, CHUNK)) # Handle final CHUNK where size might be less than CHUNK size\n",
    "\n",
    "        if cnt == 0:\n",
    "            all_data = data_int.copy()\n",
    "        else:\n",
    "            all_data = np.append(all_data, data_int, axis=0)\n",
    "        \n",
    "        cnt += 1  \n",
    "    \n",
    "    return all_data, CHUNK, RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data, CHUNK, RATE = get_audio_data()\n",
    "#audio_data = [v for chunk in audio_data for v in chunk] # Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot([v for chunk in audio_data[:100] for v in chunk])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, width=10):\n",
    "    return np.convolve(x, np.ones(width), 'valid') / width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_increasing(data):\n",
    "    data = moving_average(data, width=400)\n",
    "#     pct_increasing = sum([1 for i in range(1, len(data)) if data[i] > data[i-1]])/len(data)\n",
    "#     return pct_increasing > 0.5\n",
    "    return np.mean(np.diff(data, n=2)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = [np.max(r) for r in audio_data]\n",
    "seconds = [(CHUNK / RATE)*i for i in range(len(audio_data))]\n",
    "\n",
    "plot_time = 20 # seconds\n",
    "amp_thresh = 1000000000\n",
    "\n",
    "# Get samples above threshold amplitude if they are rising and not falling\n",
    "abv_thresh = [np.max(d) > amp_thresh and is_increasing(d) for d in audio_data]\n",
    "#rising = [True if np.mean(c[:512]) < np.mean(c[512:]) else False for c in audio_data]\n",
    "#abv_thresh = [r and a for r, a in zip(rising, abv_thresh)]\n",
    "\n",
    "to_idx = np.where(np.array(seconds) > plot_time)[0][0] # Convert plot time in seconds to matching index\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.plot(seconds[:to_idx], max_data[:to_idx])\n",
    "plt.plot([seconds[i] for i, v in enumerate(abv_thresh[:to_idx]) if v == True], [amp_thresh for v in abv_thresh[:to_idx] if v == True], 'ro')\n",
    "#plt.plot([seconds[i] for i, v in enumerate(max_data[:to_idx]) if v > amp_thresh], [v for v in max_data[:to_idx] if v > amp_thresh], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERATION_CNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK = Audio.CHUNK\n",
    "# Audio.open_stream()\n",
    "# p = Audio.p\n",
    "# wf = Audio.wf\n",
    "# data = wf.readframes(CHUNK)\n",
    "\n",
    "# fifo_long = Audio.init_fifo_from_preprocessed_data(n_data, Audio.FIFO_LONG_LEN)\n",
    "# fifo_short = Audio.init_fifo_from_preprocessed_data(n_data, Audio.FIFO_SHORT_LEN)\n",
    "\n",
    "# for sample_idx in range(len(n_data)):\n",
    "#     Audio.stream.write(data)\n",
    "#     data = wf.readframes(CHUNK)\n",
    "#     if len(data) < CHUNK:\n",
    "#         break\n",
    "\n",
    "#     lfb = n_data[sample_idx]  # Log of the frequencies for each bucket\n",
    "\n",
    "#     # Get rolling average & min\n",
    "#     roll_delta, fifo_long, fifo_short = Audio.get_roll_delta(fifo_long, fifo_short, lfb)\n",
    "#     #print(np.max(roll_delta))\n",
    "#     if np.max(roll_delta) > 0.05:\n",
    "#         print(np.max(roll_delta))\n",
    "# #     if np.max(lfb) > .37:\n",
    "# #         print(np.max(lfb))\n",
    "    \n",
    "#     if sample_idx > ITERATION_CNT:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK/RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio_data)*(CHUNK/RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "reset_delta [ms]: length of time (in ms) to wait before a new split can occur \n",
    "'''\n",
    "def get_split_times(data, reset_delta=125, chunk=CHUNK, rate=RATE):\n",
    "    reset_delta_frames = int(reset_delta / ((chunk / rate)*1000)) + 2\n",
    "    #reset_delta_frames = int((125/1000)*RATE)+1\n",
    "    \n",
    "    abv_thresh = [np.max(d) > amp_thresh and is_increasing(d) for d in audio_data]\n",
    "    times = []\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        if abv_thresh[i] == True:\n",
    "            times += [i*CHUNK/RATE]\n",
    "            i += reset_delta_frames\n",
    "        else:\n",
    "            i += 1\n",
    "            \n",
    "        if i >= len(abv_thresh):\n",
    "            # Add final time\n",
    "            times += [len(audio_data)*(CHUNK/RATE)]\n",
    "            break\n",
    "    \n",
    "    return times\n",
    "\n",
    "times = get_split_times(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Music Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mv_clips(clips, times):\n",
    "    cut_lens = np.diff([0] + times)\n",
    "\n",
    "    mv_clips = []\n",
    "    for cut_len in tqdm(cut_lens):\n",
    "\n",
    "        clip_len = 0\n",
    "        while clip_len < cut_len:\n",
    "            if clips: # If not empty\n",
    "                clip = clips.pop(0)\n",
    "                clip_len = clip.duration\n",
    "                if clip_len > cut_len:\n",
    "                    mv_clips += [clip.subclip(0, cut_len)]\n",
    "            else:\n",
    "                print('Out of clips')\n",
    "\n",
    "                if VID_FILES: # Get next video and separate in to clips\n",
    "                    print('Getting next video, {}...'.format(VID_FILES[0].split('\\\\')[-1]))\n",
    "                    video = VideoFileClip(VID_FILES.pop(0))\n",
    "                    clips = split_video(video)\n",
    "                    print(f'{len(clips)} new clips created. Continuing music video creating...')\n",
    "                else: # No more videos, break\n",
    "                    print('No more videos available')\n",
    "                    return mv_clips\n",
    "    return mv_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clips = build_mv_clips(clips, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_video = concatenate_videoclips(mv_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_audio = AudioFileClip(FINAL_AUDIO).subclip(0, music_video.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_music_video = music_video.set_audio(music_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = 'music_video.mp4'\n",
    "i = 1\n",
    "# Append unique id suffix to filename if file already exists\n",
    "while os.path.exists(export_name):\n",
    "    i += 1\n",
    "    export_name = export_name.split('.')[0] + str(i) + '.' + export_name.split('.')[-1]\n",
    "print(export_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_music_video.write_videofile(export_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
