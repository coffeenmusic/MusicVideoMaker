{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import print_frame\n",
    "from moviepy.editor import concatenate_videoclips, VideoFileClip, AudioFileClip\n",
    "from video import split_video\n",
    "from audio import get_audio_data, get_saved_audio, get_split_times, is_increasing\n",
    "from other import get_unique_filename\n",
    "from music_video import get_clips, build_mv_clips\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "VID_DIR = os.path.join('Media', 'Videos')\n",
    "VID_FILES = [os.path.join(VID_DIR, f) for f in os.listdir(VID_DIR) if f.split('.')[-1].lower() in ['mp4', 'avi', 'mkv', 'm4v']]\n",
    "print(f'{len(VID_FILES)} videos found.', [f.split('\\\\')[-1] for f in VID_FILES])\n",
    "\n",
    "# Audio to split clips from\n",
    "AUD_DIR = os.path.join('Media', 'Audio')\n",
    "AUD_FILE = os.path.join(AUD_DIR, 'galaxy rise - drums.wav')\n",
    "print(AUD_FILE)\n",
    "\n",
    "# Audio to stitch to final video\n",
    "FINAL_AUDIO = os.path.join(AUD_DIR, 'greydon square - galaxy rise.wav')\n",
    "\n",
    "EXPORT_FILENAME = 'music_video.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Create tool to find best audio split points\n",
    "- Clean up print_frame debug in functions once no longer being used\n",
    "- Export clips to clip folder\n",
    "- Create threshold visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potentionally Useful Functions\n",
    "- clip.get_frame(time)\n",
    "- clip.ipython_display(width=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video = VideoFileClip(VID_FILES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Frames/Second:', video.reader.fps)\n",
    "# print('Frame Count:', video.reader.nframes)\n",
    "# print('Video Length:', video.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_frame(video.get_frame(np.random.randint(0, video.duration)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Video In To Clips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_data = get_saved_audio(AUD_FILE)\n",
    "if saved_data:\n",
    "    audio_data, CHUNK, RATE = saved_data\n",
    "else:\n",
    "    audio_data, CHUNK, RATE = get_audio_data(AUD_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot([v for chunk in audio_data[:100] for v in chunk])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = [np.max(r) for r in audio_data]\n",
    "seconds = [(CHUNK / RATE)*i for i in range(len(audio_data))]\n",
    "\n",
    "plot_time = 40 # seconds\n",
    "amp_thresh = 900000000\n",
    "\n",
    "# Get samples above threshold amplitude if they are rising and not falling\n",
    "abv_thresh = [np.max(d) > amp_thresh and is_increasing(d) for d in audio_data]\n",
    "#rising = [True if np.mean(c[:512]) < np.mean(c[512:]) else False for c in audio_data]\n",
    "#abv_thresh = [r and a for r, a in zip(rising, abv_thresh)]\n",
    "\n",
    "to_idx = np.where(np.array(seconds) > plot_time)[0][0] # Convert plot time in seconds to matching index\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.plot(seconds[:to_idx], max_data[:to_idx])\n",
    "plt.plot([seconds[i] for i, v in enumerate(abv_thresh[:to_idx]) if v == True], [amp_thresh for v in abv_thresh[:to_idx] if v == True], 'ro')\n",
    "#plt.plot([seconds[i] for i, v in enumerate(max_data[:to_idx]) if v > amp_thresh], [v for v in max_data[:to_idx] if v > amp_thresh], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = get_split_times(audio_data, RATE, amp_thresh, chunk=CHUNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERATION_CNT = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK = Audio.CHUNK\n",
    "# Audio.open_stream()\n",
    "# p = Audio.p\n",
    "# wf = Audio.wf\n",
    "# data = wf.readframes(CHUNK)\n",
    "\n",
    "# fifo_long = Audio.init_fifo_from_preprocessed_data(n_data, Audio.FIFO_LONG_LEN)\n",
    "# fifo_short = Audio.init_fifo_from_preprocessed_data(n_data, Audio.FIFO_SHORT_LEN)\n",
    "\n",
    "# for sample_idx in range(len(n_data)):\n",
    "#     Audio.stream.write(data)\n",
    "#     data = wf.readframes(CHUNK)\n",
    "#     if len(data) < CHUNK:\n",
    "#         break\n",
    "\n",
    "#     lfb = n_data[sample_idx]  # Log of the frequencies for each bucket\n",
    "\n",
    "#     # Get rolling average & min\n",
    "#     roll_delta, fifo_long, fifo_short = Audio.get_roll_delta(fifo_long, fifo_short, lfb)\n",
    "#     #print(np.max(roll_delta))\n",
    "#     if np.max(roll_delta) > 0.05:\n",
    "#         print(np.max(roll_delta))\n",
    "# #     if np.max(lfb) > .37:\n",
    "# #         print(np.max(lfb))\n",
    "    \n",
    "#     if sample_idx > ITERATION_CNT:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Music Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_generator = get_clips(VID_FILES, single=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "mv_clips = build_mv_clips(times, clip_generator)\n",
    "print('Time taken:', (time.time() - start_time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_video = concatenate_videoclips(mv_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_audio = AudioFileClip(FINAL_AUDIO).subclip(0, music_video.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_music_video = music_video.set_audio(music_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = get_unique_filename(EXPORT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_music_video.write_videofile(export_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
